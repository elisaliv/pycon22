## Writing faster Python 3 
### Sebastian Witowski

[GitHub repo](https://github.com/switowski/writing-faster-python3)

[Blog](https://switowski.com/tag/writing-faster-python/)

### For loops
[...]

Optimization is often a trade-off between speed and memory efficiency. E.g.:
list comprehension (example 3) is faster, generator expression (example 4) more
memory-efficient. 

Example 5: numpy is more efficient for numbers in general. But the first time I
run it measuring its time execution with benchmarking, it takes longer than the
second time because of the `import` time.

- use local variables
- built-in functions (itertools, collections)
- list comprehension instead of loop (for speed)
- or generator expression for lower memory usage
- use numpy for scientific computing

--> this was source code optimization.

### Benchmarks setup
It's important to know which Python version you are using and the machine (to
compare benchmarks). But improved code will always be relatively faster on the
same machine etc.

### Permission vs. forgiveness
Check if a file exists and if you can access it before reading it --> you can do
it with `if`s or with a `try-except` block: asking for permission is slower,
especially if we have to check many different attributes. But if we are missing
attributes, handling exceptions takes more time --> 

**We have to think if it's more likely that my code will throw an exception or
not**. 

### Find element in a collection
We want to pick the first element between 1 and 10000 that is divisible by 42
and 43. 

First, we can use a `for` loop and check with an `if`. Or we can use a generator
expression, but it's not really efficient. It's better to use a lazy generator
expression. 

The `for` + `if` can be easier and more readable, while the lazy generator
expression is more coincise. 

### Filter a list
We can use `for` + `if` again, or the `filter` function, or use a list
comprehension. 

- list comprehension: when we need a list
- filter: when we need an iterator
- `for` + `if`: for complex conditions that you can't put in a list
  comprehension 

### Membership testing
Check if an element exists within a list: `for` + `if` vs. `in` operator: for
many different scenarios (number at the beginning/end middle of the list), the
`in` operator is always faster. 

But we can do better with a `set` instead of `list` --> the lookup time is
constant, independently on the position of the number (O(1)).

If we consider also the time of converting a list to a set when measuring the
lookup time, however, using the list directly is faster: converting a list to a
set is slow --> set is not a drop-in replacement for a list!

### Creating a dictionary: `dict() vs. {}`
For an empty dictionary, it's faster with `{}`. Why? We can dig deeper using the
`dis` library, that prints what is happening under the hood. When you use
`dict`, Python has to check whether you have overridden the function first. 

In general, `{}, [], ()` are faster than `dict(), list(), tuple()`.

### Remove duplicates
List comprehensions must only be used to **create** a list --> don't use them
for their side-effects! 

In this case, it is faster to create a `set` from the list containing
duplicates, and then re-converting it to a `list`. Or converting a
`dict.fromkeys(duplicates)` to a list --> but this only works with hashable
keys.

### Different Python versions
Just for fun, he checked out the performances with different Python versions
using `pyenv`, in the end comparing versions 3.7 vs. 3.11 --> we see there are a
lot of improvements in Python 3.11. Why? Check out Mark Shannon --> he improved
the Cython performances. 

### Conclusion
It's important to understand data structure to optimize your source code, and
it's also important to work to optimize your code to get a better understanding
of data structures and what your code does.

But you shouldn't sacrifice readability for small performance improvements. 
## Generazione di file PDF con Transformers per affinamento dell'object detection in documenti testuali
### Lorenzo Pisaneschi - Nephila

* [Slides](https://github.com/pisalore/pycon22/blob/master/pycon22.ipynb)
* [Tesi](https://github.com/pisalore/master_thesis)

**Document layout analysis**
Cos'è? Tecnica per capire il layout di un file, dunque anche facendo text
mining.
Testo = dati non strutturati --> dobbiamo pre-processarli in qualche modo.
Idee per risolvere i problemi: 
- usare un piccolo dataset iniziale
- implementare una pipeline per annotare automaticamente
- ristrutturare il dataset iniziale in modo strutturato

**Dataset**
375 pdf = 2088 pagine --> dataset molto piccolo per ML. Sono pdf di articoli
scientifici (layout specifico).

**Semi-automatic annotation pipeline**
- input = PDF --> vengono convertiti in XML TEI tramite GROBID
- parsing (PDFMiner/beautifulsoup4 per XML)
- generazione delle annotazioni
  
GROBID converte i PDF in XML --> dati strutturati --> riusciamo ad accedere a
informazioni altrimenti inaccessibili. 
Con GROBID isoliamo delle informazioni importanti, per es. autore articolo, anno
di pubblicazione etc.

Una volta ristrutturato il dato, possiamo passare al parsing: PDFMinder e
beautifulsoup4 vengono usati contemporaneamente. Con PDFMiner estraiamo testo e
immagini, con beautifulsoup4 testo, tabelle, riferimenti e formule (sapendo già
cosa stiamo estraendo). Poi facendo text matching allineiamo i due risultati -->
siamo in grado di etichettare i dati. 

L'allineamento viene fatto con un parser (funzione `parse_doc`) --> salva le
pagine come PNG e poi salva le annotazioni in un dizionario serializzato.
`parse_doc` è la funzione fondamentale in questo processo.

Con PDFMiner estraiamo semplicemente il testo, invece con beautifulsoup4
esponiamo le proprietà del file --> poi possiamo fare il matching.

Le annotazioni corrispondono a dizionari con sotto-dizionari, per tutte le
diverse categorie. Poiché ci sono alcuni errori, facciamo delle modifiche
manuali (formato PASCAL VOC).
Annotazioni --> in formato COCO.

Quindi ora abbiamo il dataset ristrutturato e corretto --> passiamo all'uso dei
Transformers. Metodo molto famoso e usato per NLP. Lui ha provato a usarlo per
apprendere le relazioni che esistono tra gli oggetti nel file.
--> impara lo schema del layout e ne genera di nuovi.

Addestriamo LayoutTransformer a riconoscere il layout --> passiamo all'inferenza
= generazione di nuovi layout.

I layout generati vengono salvati in formato json + png per vederli. 
È stato necessario un po' di post-processing perché c'era un po' di rumore (i
dati di partenza erano pochi).

**Automatic document generation**
Generato il layout, ora vogliamo generare i documenti (PDF) veri e propri.
1) Generazione del testo (scopo puramente accademico) + frasi
2) Selezione del layout
3) Generazione del PDF con FPDF
4) Immagini e tabelle: scaricate da internet, ridimensionate e tagliate in base
   ai bounding box
5) Formule: anch'esse scaricate da internet, inserite con `pylatex`

**Method evaluation and conclusions**
Per valutare il modello hanno usato ResNeXt --> ...funziona bene.

Quindi Transformer può essere usato anche per task al di fuori di NLP, inoltre
hanno migliorato la performance con il metodo generativo.

---

### Q&A
Quanto può essere generalizzato questo metodo, visto che i PDF degli articoli
hanno una struttura abbastanza standard? 
Questo è il layout che hanno studiato di più e approfondito per la tesi
(articoli di conferenze di 2 colonne), però ne hanno provati anche altri (sempre
di articoli).

Casi d'uso aziendali che si possono pensare: documenti amministrativi, ospedali,
... 

Ci sono tantissimi tipi di pdf diversi --> per questo c'è bisogno di una
pipeline software e non è possibile usare un approccio solo ML. Inoltre loro per
alleggerire la fase di addestramento non hanno usato il riconoscimento delle
immagini. 